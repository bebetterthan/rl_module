{
  "scenarios_file": "../data/phase1b_train_80_augmented.json",
  "total_scenarios": 80,
  "agent": "hardcoded_comprehensive",
  "runs": 100,
  "statistics": {
    "mean_reward": 4129.57,
    "std_reward": 2238.113769471963,
    "min_reward": 1506.0,
    "max_reward": 8940.0,
    "median_reward": 3066.0,
    "ci_95_lower": 3690.899701183495,
    "ci_95_upper": 4568.240298816505
  },
  "behavioral": {
    "mean_episode_length": 3.0,
    "nmap_usage_pct": 100.0
  },
  "all_rewards": [
    2347.0,
    7630.0,
    3745.0,
    1506.0,
    7598.0,
    2619.0,
    7193.0,
    2325.0,
    6793.0,
    2347.0,
    7288.0,
    2325.0,
    7048.0,
    2047.0,
    7228.0,
    3067.0,
    8673.0,
    2067.0,
    2408.0,
    2822.0,
    2283.0,
    2408.0,
    2822.0,
    7690.0,
    3745.0,
    8837.0,
    2028.0,
    7285.0,
    7598.0,
    3008.0,
    6793.0,
    3066.0,
    3527.0,
    2822.0,
    7048.0,
    3008.0,
    7285.0,
    2774.0,
    2774.0,
    2164.0,
    2067.0,
    2408.0,
    8651.0,
    2164.0,
    8940.0,
    5938.0,
    2067.0,
    2752.0,
    2582.0,
    3985.0,
    7288.0,
    3745.0,
    3745.0,
    2325.0,
    7285.0,
    1506.0,
    7193.0,
    3745.0,
    2273.0,
    3066.0,
    1823.0,
    2731.0,
    7193.0,
    3067.0,
    3745.0,
    3267.0,
    3944.0,
    2619.0,
    3008.0,
    2347.0,
    2347.0,
    7225.0,
    1823.0,
    2047.0,
    3007.0,
    3483.0,
    4148.0,
    2282.0,
    2164.0,
    2347.0,
    2822.0,
    3067.0,
    3966.0,
    4220.0,
    4220.0,
    2582.0,
    2822.0,
    6945.0,
    3483.0,
    2273.0,
    8651.0,
    3066.0,
    7288.0,
    6793.0,
    7215.0,
    2709.0,
    7978.0,
    2282.0,
    2347.0,
    1845.0
  ]
}